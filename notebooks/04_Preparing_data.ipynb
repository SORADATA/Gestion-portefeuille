{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b40398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ DonnÃ©es chargÃ©es : (106019, 16)\n",
      "ğŸ§¹ Nettoyage : 0 lignes supprimÃ©es (0.0%)\n",
      "\n",
      "ğŸ“Š Distribution de la Target (Horizon=5j) :\n",
      "Target\n",
      "1    0.538718\n",
      "0    0.461282\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "âœ… Datasets sauvegardÃ©s :\n",
      "   ğŸ“ Train:  74,061 lignes (2015-01-30 â†’ 2022-09-07)\n",
      "   ğŸ“ Test:   31,768 lignes (2022-09-08 â†’ 2025-12-12)\n",
      "   ğŸ“ Full:   105,829 lignes\n",
      "\n",
      "ğŸ” Features disponibles : 13\n",
      "ğŸ¯ Target : 2 classes\n",
      "ğŸ·ï¸ Clusters : 5 groupes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# --- 1. CONFIGURATION ---\n",
    "PROJECT_ROOT = Path(\"/home/onyxia/work/Gestion-portefeuille/\")\n",
    "INPUT_PATH = PROJECT_ROOT / \"data/interim/cac40_interim_features.csv\"\n",
    "CLUSTERS_PATH = PROJECT_ROOT / \"data/processed/clusters_mapping.csv\"\n",
    "OUTPUT_DIR = PROJECT_ROOT / \"data/processed\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "TARGET_HORIZON = 5 # Jours dans le futur\n",
    "\n",
    "\n",
    "# --- 2. CHARGEMENT ---\n",
    "df = pd.read_csv(INPUT_PATH, parse_dates=['Date'])\n",
    "df_clusters = pd.read_csv(CLUSTERS_PATH, index_col='Ticker')\n",
    "cluster_map = df_clusters['Cluster'].to_dict()\n",
    "\n",
    "\n",
    "print(f\"ğŸ“¥ DonnÃ©es chargÃ©es : {df.shape}\")\n",
    "\n",
    "\n",
    "# --- 3. INJECTION DES CLUSTERS ---\n",
    "df['Cluster'] = df['Ticker'].map(cluster_map)\n",
    "\n",
    "\n",
    "# VÃ©rifier les tickers sans cluster\n",
    "missing_clusters = df[df['Cluster'].isna()]['Ticker'].unique()\n",
    "if len(missing_clusters) > 0:\n",
    "    print(f\"âš ï¸ {len(missing_clusters)} tickers sans cluster : {missing_clusters.tolist()}\")\n",
    "    df = df.dropna(subset=['Cluster'])\n",
    "\n",
    "\n",
    "# --- 4. CRÃ‰ATION DE LA TARGET ---\n",
    "df = df.sort_values(['Ticker', 'Date']).reset_index(drop=True)\n",
    "df['Target_Price'] = df.groupby('Ticker')['Close'].shift(-TARGET_HORIZON)\n",
    "df['Target'] = (df['Target_Price'] > df['Close']).astype(int)\n",
    "\n",
    "\n",
    "# --- 5. NETTOYAGE ---\n",
    "# Supprimer les derniers jours sans Target\n",
    "df = df.dropna(subset=['Target_Price'])\n",
    "\n",
    "\n",
    "# Identifier les features\n",
    "feature_cols = [c for c in df.columns \n",
    "                if c not in ['Date', 'Ticker', 'Target_Price', 'Target', 'Cluster', 'Close']]\n",
    "\n",
    "\n",
    "# Supprimer lignes avec NaN dans les features\n",
    "initial_len = len(df)\n",
    "df = df.dropna(subset=feature_cols)\n",
    "print(f\"ğŸ§¹ Nettoyage : {initial_len - len(df)} lignes supprimÃ©es ({100*(1-len(df)/initial_len):.1f}%)\")\n",
    "\n",
    "\n",
    "# --- 6. ANALYSE DE LA TARGET ---\n",
    "target_dist = df['Target'].value_counts(normalize=True)\n",
    "print(f\"\\nğŸ“Š Distribution de la Target (Horizon={TARGET_HORIZON}j) :\")\n",
    "print(target_dist)\n",
    "\n",
    "\n",
    "if target_dist.max() > 0.65:\n",
    "    print(\"âš ï¸ Classes dÃ©sÃ©quilibrÃ©es dÃ©tectÃ©es !\")\n",
    "\n",
    "\n",
    "# --- 7. SÃ‰PARATION TEMPORELLE ---\n",
    "df = df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "train_end = df['Date'].quantile(0.70)\n",
    "\n",
    "df_train = df[df['Date'] < train_end]\n",
    "df_test = df[df['Date'] >= train_end]\n",
    "\n",
    "\n",
    "# --- 8. SAUVEGARDE ---\n",
    "df_train.to_csv(OUTPUT_DIR / \"train.csv\", index=False)\n",
    "df_test.to_csv(OUTPUT_DIR / \"test.csv\", index=False)\n",
    "df.to_csv(OUTPUT_DIR / \"cac40_final_superset.csv\", index=False)\n",
    "\n",
    "\n",
    "print(f\"\\nâœ… Datasets sauvegardÃ©s :\")\n",
    "print(f\"   ğŸ“ Train:  {len(df_train):,} lignes ({df_train['Date'].min().date()} â†’ {df_train['Date'].max().date()})\")\n",
    "print(f\"   ğŸ“ Test:   {len(df_test):,} lignes ({df_test['Date'].min().date()} â†’ {df_test['Date'].max().date()})\")\n",
    "print(f\"   ğŸ“ Full:   {len(df):,} lignes\")\n",
    "\n",
    "\n",
    "# --- 9. VÃ‰RIFICATIONS FINALES ---\n",
    "print(f\"\\nğŸ” Features disponibles : {len(feature_cols)}\")\n",
    "print(f\"ğŸ¯ Target : {df['Target'].nunique()} classes\")\n",
    "print(f\"ğŸ·ï¸ Clusters : {df['Cluster'].nunique()} groupes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
