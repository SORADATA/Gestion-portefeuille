{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a48fc09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ √âtape 2 : Chargement et Feature Engineering...\n",
      "üì• Chargement et fusion de 38 fichiers...\n",
      "‚ö†Ô∏è Colonne 'Dividends' ajout√©e avec des z√©ros.\n",
      "üîß Calcul des features de risque et de performance...\n",
      "üíæ Feature Engineering termin√©. Donn√©es sauv√©es vers : /home/onyxia/work/Gestion-portefeuille/data/interim/cac40_interim_features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# --- CHEMINS ABSOLUS STATIQUES ---\n",
    "# üõë ATTENTION : Ce chemin doit correspondre EXACTEMENT √† la racine de votre projet.\n",
    "PROJECT_ROOT_ABSOLUTE = \"/home/onyxia/work/Gestion-portefeuille/\" \n",
    "\n",
    "try:\n",
    "    ROOT_DIR = Path(PROJECT_ROOT_ABSOLUTE)\n",
    "except Exception:\n",
    "    ROOT_DIR = Path.cwd() \n",
    "\n",
    "# Chemins pour l'entr√©e et la sortie\n",
    "RAW_DATA_PATH = ROOT_DIR / \"data\" / \"raw\"\n",
    "INTERIM_DATA_PATH = ROOT_DIR / \"data\" / \"interim\"\n",
    "PROCESSED_DATA_PATH = ROOT_DIR / \"data\" / \"processed\"\n",
    "OUTPUT_FILENAME = \"cac40_interim_features.csv\"\n",
    "LAG_WINDOW = 20  # Fen√™tre pour les calculs glissants\n",
    "\n",
    "# --- 1. FONCTION DE CHARGEMENT ET FUSION (CORRECTION DU TYPE DE DONN√âES) ---\n",
    "def load_and_merge_data(raw_path: Path = RAW_DATA_PATH) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Charge tous les fichiers CSV, les fusionne, et corrige les types de donn√©es \n",
    "    pour √©viter les TypeErrors dans les calculs (conversion forc√©e en float).\n",
    "    \"\"\"\n",
    "    all_files = glob(str(raw_path / \"*.csv\")) \n",
    "    \n",
    "    if not all_files:\n",
    "        print(f\"‚ùå Erreur : Aucun fichier CSV trouv√© dans {raw_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    list_df = []\n",
    "    print(f\"üì• Chargement et fusion de {len(all_files)} fichiers...\")\n",
    "    for filename in all_files:\n",
    "        try:\n",
    "            # Lire la Date comme une colonne nomm√©e\n",
    "            # (n√©cessite que le script de t√©l√©chargement utilise df.reset_index(names=['Date']))\n",
    "            df = pd.read_csv(filename, parse_dates=['Date']) \n",
    "            list_df.append(df)\n",
    "        except Exception as e:\n",
    "            # Si la lecture √©choue, on continue\n",
    "            print(f\"‚ùå Erreur de chargement pour {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if list_df:\n",
    "        full_df = pd.concat(list_df)\n",
    "        \n",
    "        # --- CORRECTION CLE : Conversion de Type Forc√©e ---\n",
    "        # Colonnes qui doivent absolument √™tre num√©riques pour les calculs\n",
    "        cols_to_convert = ['Adj Close', 'Volume', 'Dividends']\n",
    "        \n",
    "        for col in cols_to_convert:\n",
    "            if col in full_df.columns:\n",
    "                # 'errors=\"coerce\"' convertit les strings non num√©riques en NaN\n",
    "                full_df[col] = pd.to_numeric(full_df[col], errors='coerce')\n",
    "            elif col == 'Dividends':\n",
    "                # Si la colonne 'Dividends' n'existe pas, la cr√©er avec des z√©ros.\n",
    "                full_df[col] = 0.0\n",
    "                print(f\"‚ö†Ô∏è Colonne '{col}' ajout√©e avec des z√©ros.\")\n",
    "        \n",
    "        # Le MultiIndex est cr√©√© √† partir des colonnes 'Ticker' et 'Date'\n",
    "        # On s'assure que toutes les lignes ont une valeur Ticker et Date avant de set_index\n",
    "        full_df = full_df.dropna(subset=['Ticker', 'Date']) \n",
    "        full_df = full_df.set_index(['Ticker', 'Date']).sort_index()\n",
    "        \n",
    "        # On ne garde que les colonnes pertinentes\n",
    "        return full_df.loc[:, ['Adj Close', 'Volume', 'Dividends']].copy()\n",
    "    return pd.DataFrame()\n",
    "\n",
    "# --- 2. FONCTION DE CALCUL DES FEATURES ---\n",
    "def compute_financial_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" Calcule les indicateurs cl√©s (Returns, Volatility, Momentum, Sharpe) pour le clustering. \"\"\"\n",
    "    if df.empty: return df\n",
    "\n",
    "    # Le calcul est appliqu√© par groupe de Ticker (groupby(level='Ticker'))\n",
    "    grouped = df.groupby(level='Ticker')\n",
    "\n",
    "    print(\"üîß Calcul des features de risque et de performance...\")\n",
    "    \n",
    "    df['Returns'] = grouped['Adj Close'].pct_change()\n",
    "    \n",
    "    # Volatilit√© annualis√©e (√âcart-type glissant)\n",
    "    df['Volatility'] = grouped['Returns'].transform(\n",
    "        lambda x: x.rolling(window=LAG_WINDOW).std() * np.sqrt(252)\n",
    "    )\n",
    "\n",
    "    # Performance glissante (Momentum)\n",
    "    df['Performance_20D'] = grouped['Adj Close'].pct_change(LAG_WINDOW)\n",
    "\n",
    "    # Ratio de Sharpe (Approximation)\n",
    "    daily_vol_rolling = grouped['Returns'].transform(lambda x: x.rolling(window=LAG_WINDOW).std())\n",
    "    \n",
    "    # √âvite la division par z√©ro en rempla√ßant les z√©ros dans daily_vol_rolling par NaN ou une petite valeur\n",
    "    daily_vol_rolling = daily_vol_rolling.replace(0, np.nan) \n",
    "    \n",
    "    df['Sharpe_Ratio_20D'] = grouped['Returns'].transform(\n",
    "        lambda x: x.rolling(window=LAG_WINDOW).mean() / daily_vol_rolling\n",
    "    )\n",
    "    \n",
    "    # Nettoyage et s√©lection\n",
    "    df = df.dropna()\n",
    "    \n",
    "    # R√©initialisation de l'index pour que Ticker et Date redeviennent des colonnes\n",
    "    features_df = df.reset_index()\n",
    "    \n",
    "    # Gardons seulement les colonnes finales n√©cessaires\n",
    "    return features_df.loc[:, ['Date', 'Ticker', 'Adj Close', 'Volume', 'Returns', 'Volatility', 'Performance_20D', 'Sharpe_Ratio_20D', 'Dividends']]\n",
    "\n",
    "\n",
    "def run_feature_engineering():\n",
    "    \"\"\" Orchestre le chargement, le calcul et la sauvegarde des features. \"\"\"\n",
    "    print(\"üöÄ √âtape 2 : Chargement et Feature Engineering...\")\n",
    "    \n",
    "    # 1. Chargement et fusion des donn√©es brutes\n",
    "    full_data = load_and_merge_data(raw_path=RAW_DATA_PATH)\n",
    "    \n",
    "    if full_data.empty:\n",
    "        print(\"‚ùå Processus interrompu: Impossible de charger les donn√©es brutes.\")\n",
    "        return\n",
    "\n",
    "    # 2. Calcul des features\n",
    "    features_df = compute_financial_features(full_data)\n",
    "    \n",
    "    if features_df.empty:\n",
    "        print(\"‚ùå Processus interrompu: Aucune donn√©e restante apr√®s nettoyage des NaN.\")\n",
    "        return\n",
    "\n",
    "    # 3. Sauvegarde dans le dossier 'interim'\n",
    "    os.makedirs(INTERIM_DATA_PATH, exist_ok=True)\n",
    "    output_filepath = os.path.join(INTERIM_DATA_PATH, OUTPUT_FILENAME)\n",
    "    \n",
    "    features_df.to_csv(output_filepath, index=False)\n",
    "    print(f\"üíæ Feature Engineering termin√©. Donn√©es sauv√©es vers : {output_filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_feature_engineering()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
