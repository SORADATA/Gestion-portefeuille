{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48fc09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FEATURE ENGINEERING AM√âLIOR√â - CAC40\n",
      "============================================================\n",
      "üì• Chargement de 38 fichiers...\n",
      "‚úÖ 106779 observations charg√©es\n",
      "üîß Calcul de 15 features essentielles...\n",
      "‚úÖ 106019 observations apr√®s feature engineering\n",
      "‚úÖ 12 features cr√©√©es\n",
      "\n",
      "üíæ Donn√©es sauvegard√©es : /home/onyxia/work/Gestion-portefeuille/data/interim/cac40_interim_features.csv\n",
      "\n",
      "üìä Aper√ßu des features :\n",
      "                   count                           mean                  min  \\\n",
      "Date              106019  2020-07-12 00:52:15.920920064  2015-01-30 00:00:00   \n",
      "Close           106019.0                     190.063469                1.313   \n",
      "Volume          106019.0                 2020907.569596                  0.0   \n",
      "Returns_1D      106019.0                       0.001234            -0.985377   \n",
      "Returns_5D      106019.0                       0.004826            -0.997102   \n",
      "Returns_20D     106019.0                       0.022157            -0.997335   \n",
      "Vol_20D         106019.0                       0.327736             0.047063   \n",
      "RSI_14          106019.0                      52.542575                  0.0   \n",
      "MACD_Histogram  106019.0                      -0.001327          -805.339622   \n",
      "Price_to_SMA20  106019.0                       1.003103             0.005088   \n",
      "BB_Position     106019.0                       0.539876            -0.554438   \n",
      "Volume_Ratio    106019.0                       1.007816                  0.0   \n",
      "Sharpe_20D      106019.0                        0.04717            -1.051516   \n",
      "Drawdown_20D    106019.0                      -0.042904            -0.998421   \n",
      "Momentum_Score  106019.0                       0.013491            -0.995151   \n",
      "\n",
      "                                25%                  50%                  75%  \\\n",
      "Date            2017-10-19 00:00:00  2020-07-16 00:00:00  2023-03-29 00:00:00   \n",
      "Close                     22.675409            47.811378           104.857452   \n",
      "Volume                     447094.0            1040941.0            2468413.0   \n",
      "Returns_1D                -0.008236             0.000508             0.009339   \n",
      "Returns_5D                -0.018375             0.003086               0.0238   \n",
      "Returns_20D               -0.034345             0.010047             0.054039   \n",
      "Vol_20D                    0.174064             0.231762             0.316698   \n",
      "RSI_14                    40.529518            52.658486            64.643599   \n",
      "MACD_Histogram            -0.148314             0.002638             0.156673   \n",
      "Price_to_SMA20             0.980406              1.00524             1.028506   \n",
      "BB_Position                0.280918             0.568742             0.801667   \n",
      "Volume_Ratio               0.743424             0.921864             1.157735   \n",
      "Sharpe_20D                -0.106835             0.043907             0.199168   \n",
      "Drawdown_20D              -0.059417            -0.026927            -0.006956   \n",
      "Momentum_Score            -0.022478             0.006931             0.035726   \n",
      "\n",
      "                                max             std  \n",
      "Date            2025-12-19 00:00:00             NaN  \n",
      "Close                       10130.0       667.21163  \n",
      "Volume                  139455018.0  2786502.299194  \n",
      "Returns_1D                85.278784        0.262739  \n",
      "Returns_5D                83.316731        0.392152  \n",
      "Returns_20D              206.534972        1.267333  \n",
      "Vol_20D                  302.910311        4.157604  \n",
      "RSI_14                        100.0       17.008274  \n",
      "MACD_Histogram           778.051769        9.614293  \n",
      "Price_to_SMA20            16.223787        0.075092  \n",
      "BB_Position                 1.56213        0.323578  \n",
      "Volume_Ratio              18.205121        0.462586  \n",
      "Sharpe_20D                 1.224084        0.225686  \n",
      "Drawdown_20D                    0.0        0.055446  \n",
      "Momentum_Score           105.398655        0.724208  \n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# FEATURE ENGINEERING - CAC40\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "PROJECT_ROOT = \"/home/onyxia/work/Gestion-portefeuille/\"\n",
    "ROOT_DIR = Path(PROJECT_ROOT)\n",
    "RAW_DATA_PATH = ROOT_DIR / \"data\" / \"raw\"\n",
    "PROCESSED_DATA_PATH = ROOT_DIR / \"data\" / \"processed\"\n",
    "PROCESSED_DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"FEATURE ENGINEERING - CAC40\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ============================================\n",
    "# 1. CHARGEMENT DU DATASET GLOBAL\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n √âTAPE 1 : Chargement du dataset...\")\n",
    "\n",
    "dataset_path = RAW_DATA_PATH / \"cac40_dataset.csv\"\n",
    "\n",
    "if not dataset_path.exists():\n",
    "    print(f\" Fichier introuvable : {dataset_path}\")\n",
    "    print(\" Lance d'abord le script de t√©l√©chargement !\")\n",
    "else:\n",
    "    # Charger avec MultiIndex\n",
    "    df = pd.read_csv(dataset_path, index_col=['date', 'ticker'], parse_dates=['date'])\n",
    "    \n",
    "    print(f\"‚úÖ Dataset charg√© : {df.shape}\")\n",
    "    print(f\"   Colonnes : {list(df.columns)}\")\n",
    "    print(f\"   Tickers : {df.index.get_level_values('ticker').nunique()}\")\n",
    "    print(f\"   P√©riode : {df.index.get_level_values('date').min().date()} ‚Üí {df.index.get_level_values('date').max().date()}\")\n",
    "    \n",
    "    print(\"\\n Aper√ßu des donn√©es :\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    print(\"\\n Info dataset :\")\n",
    "    print(df.info())\n",
    "\n",
    "# ============================================\n",
    "# 2. FONCTIONS POUR LES INDICATEURS TECHNIQUES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîß √âTAPE 2 : D√©finition des fonctions techniques...\")\n",
    "\n",
    "def rsi(series: pd.Series, window: int = 14) -> pd.Series:\n",
    "    \"\"\"RSI (Relative Strength Index).\"\"\"\n",
    "    delta = series.diff()\n",
    "    gain = delta.clip(lower=0)\n",
    "    loss = -delta.clip(upper=0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=window, min_periods=window).mean()\n",
    "    avg_loss = loss.rolling(window=window, min_periods=window).mean()\n",
    "    \n",
    "    rs = avg_gain / (avg_loss + 1e-10)\n",
    "    return 100 - (100 / (1 + rs))\n",
    "\n",
    "\n",
    "def macd(series: pd.Series, fast=12, slow=26, signal=9):\n",
    "    \"\"\"MACD (Moving Average Convergence Divergence).\"\"\"\n",
    "    ema_fast = series.ewm(span=fast, adjust=False).mean()\n",
    "    ema_slow = series.ewm(span=slow, adjust=False).mean()\n",
    "    macd_line = ema_fast - ema_slow\n",
    "    signal_line = macd_line.ewm(span=signal, adjust=False).mean()\n",
    "    return macd_line, signal_line\n",
    "\n",
    "\n",
    "def bollinger_bands(series: pd.Series, window=20, num_std=2):\n",
    "    \"\"\"Bollinger Bands.\"\"\"\n",
    "    sma = series.rolling(window=window).mean()\n",
    "    std = series.rolling(window=window).std()\n",
    "    upper = sma + (std * num_std)\n",
    "    lower = sma - (std * num_std)\n",
    "    return upper, lower, sma\n",
    "\n",
    "\n",
    "def garman_klass_volatility(group_df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Garman-Klass Volatility - Formule exacte de ton image.\"\"\"\n",
    "    high = group_df['high']\n",
    "    low = group_df['low']\n",
    "    close = group_df['close']\n",
    "    open_ = group_df['open']\n",
    "    \n",
    "    # Formule : sqrt((ln(H/L))¬≤/2 - (2ln(2)-1)(ln(C/O))¬≤)\n",
    "    hl_component = (np.log(high / low)) ** 2 / 2\n",
    "    co_component = (2 * np.log(2) - 1) * (np.log(close / open_)) ** 2\n",
    "    \n",
    "    gk_vol = np.sqrt(hl_component - co_component)\n",
    "    return gk_vol\n",
    "\n",
    "print(\"‚úÖ Fonctions techniques d√©finies (RSI, MACD, Bollinger, GK Volatility)\")\n",
    "\n",
    "# ============================================\n",
    "# 3. CALCUL DES FEATURES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüîß √âTAPE 3 : Calcul des features techniques...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Copie pour √©viter les warnings\n",
    "df_features = df.copy()\n",
    "\n",
    "# Group by ticker\n",
    "grouped = df_features.groupby(level='ticker')\n",
    "\n",
    "# --- 1. RETURNS (4 features) ---\n",
    "print(\"üìä [1/10] Calcul des Returns...\")\n",
    "df_features['returns_1d'] = grouped['close'].pct_change()\n",
    "df_features['returns_5d'] = grouped['close'].pct_change(5)\n",
    "df_features['returns_20d'] = grouped['close'].pct_change(20)\n",
    "df_features['log_returns'] = grouped['close'].transform(lambda x: np.log(x / x.shift(1)))\n",
    "\n",
    "# --- 2. GARMAN-KLASS VOLATILITY (2 features) ---\n",
    "print(\"üìä [2/10] Calcul de Garman-Klass Volatility...\")\n",
    "df_features['gk_volatility'] = grouped.apply(garman_klass_volatility).droplevel(0)\n",
    "df_features['gk_vol_20d'] = df_features.groupby(level='ticker')['gk_volatility'].transform(\n",
    "    lambda x: x.rolling(20, min_periods=5).mean()\n",
    ")\n",
    "\n",
    "# --- 3. RSI (1 feature) ---\n",
    "print(\"üìä [3/10] Calcul du RSI...\")\n",
    "df_features['rsi_14'] = grouped['close'].transform(lambda x: rsi(x, 14))\n",
    "\n",
    "# --- 4. BOLLINGER BANDS (2 features) ---\n",
    "print(\"üìä [4/10] Calcul des Bollinger Bands...\")\n",
    "bb_upper = grouped['close'].transform(lambda x: bollinger_bands(x)[0])\n",
    "bb_lower = grouped['close'].transform(lambda x: bollinger_bands(x)[1])\n",
    "bb_middle = grouped['close'].transform(lambda x: bollinger_bands(x)[2])\n",
    "\n",
    "df_features['bb_position'] = (df_features['close'] - bb_lower) / (bb_upper - bb_lower + 1e-10)\n",
    "df_features['bb_width'] = (bb_upper - bb_lower) / (bb_middle + 1e-10)\n",
    "\n",
    "# --- 5. MACD (2 features) ---\n",
    "print(\"üìä [5/10] Calcul du MACD...\")\n",
    "macd_vals = grouped['close'].transform(lambda x: macd(x)[0])\n",
    "macd_signal_vals = grouped['close'].transform(lambda x: macd(x)[1])\n",
    "df_features['macd'] = macd_vals\n",
    "df_features['macd_histogram'] = macd_vals - macd_signal_vals\n",
    "\n",
    "# --- 6. ATR (1 feature) ---\n",
    "print(\"üìä [6/10] Calcul de l'ATR...\")\n",
    "df_features['prev_close'] = grouped['close'].shift(1)\n",
    "df_features['tr'] = df_features[['high', 'low', 'prev_close']].apply(\n",
    "    lambda x: max(x['high'] - x['low'], \n",
    "                  abs(x['high'] - x['prev_close']), \n",
    "                  abs(x['low'] - x['prev_close'])), \n",
    "    axis=1\n",
    ")\n",
    "df_features['atr_14'] = df_features.groupby(level='ticker')['tr'].transform(\n",
    "    lambda x: x.rolling(14, min_periods=1).mean()\n",
    ")\n",
    "df_features.drop(['tr', 'prev_close'], axis=1, inplace=True)\n",
    "\n",
    "# --- 7. MOVING AVERAGES (3 features) ---\n",
    "print(\"üìä [7/10] Calcul des Moving Averages...\")\n",
    "df_features['sma_20'] = grouped['close'].transform(lambda x: x.rolling(20, min_periods=5).mean())\n",
    "df_features['sma_50'] = grouped['close'].transform(lambda x: x.rolling(50, min_periods=10).mean())\n",
    "df_features['price_to_sma20'] = df_features['close'] / (df_features['sma_20'] + 1e-10)\n",
    "\n",
    "# --- 8. VOLUME (3 features) ---\n",
    "print(\"üìä [8/10] Calcul des Volume features...\")\n",
    "df_features['volume_sma_20'] = grouped['volume'].transform(lambda x: x.rolling(20, min_periods=5).mean())\n",
    "df_features['volume_ratio'] = df_features['volume'] / (df_features['volume_sma_20'] + 1)\n",
    "df_features['euro_volume'] = df_features['close'] * df_features['volume']\n",
    "\n",
    "# --- 9. RISK METRICS (2 features) ---\n",
    "print(\"üìä [9/10] Calcul des Risk Metrics...\")\n",
    "rolling_mean = grouped['returns_1d'].transform(lambda x: x.rolling(20, min_periods=5).mean())\n",
    "rolling_std = grouped['returns_1d'].transform(lambda x: x.rolling(20, min_periods=5).std())\n",
    "df_features['sharpe_20d'] = rolling_mean / (rolling_std + 1e-10)\n",
    "\n",
    "rolling_max = grouped['close'].transform(lambda x: x.rolling(20, min_periods=5).max())\n",
    "df_features['drawdown_20d'] = (df_features['close'] - rolling_max) / (rolling_max + 1e-10)\n",
    "\n",
    "# --- 10. MOMENTUM COMPOSITE (1 feature) ---\n",
    "print(\"üìä [10/10] Calcul du Momentum Score...\")\n",
    "df_features['momentum_score'] = (df_features['returns_5d'] + df_features['returns_20d']) / 2\n",
    "\n",
    "print(\"\\n‚úÖ Toutes les features calcul√©es !\")\n",
    "\n",
    "# ============================================\n",
    "# 4. NETTOYAGE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüßπ √âTAPE 4 : Nettoyage des donn√©es...\")\n",
    "\n",
    "initial_rows = len(df_features)\n",
    "print(f\"   Lignes avant nettoyage : {initial_rows:,}\")\n",
    "\n",
    "# Supprimer les NaN\n",
    "df_features = df_features.dropna()\n",
    "\n",
    "final_rows = len(df_features)\n",
    "dropped_rows = initial_rows - final_rows\n",
    "print(f\"   Lignes apr√®s nettoyage : {final_rows:,}\")\n",
    "print(f\"   Lignes supprim√©es : {dropped_rows:,} ({dropped_rows/initial_rows*100:.1f}%)\")\n",
    "\n",
    "# ============================================\n",
    "# 5. STATISTIQUES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìä √âTAPE 5 : Statistiques des features...\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Liste des features cr√©√©es\n",
    "feature_cols = [col for col in df_features.columns \n",
    "                if col not in ['close', 'high', 'low', 'open', 'volume']]\n",
    "\n",
    "print(f\"\\n‚úÖ DATASET FINAL :\")\n",
    "print(f\"   Shape : {df_features.shape}\")\n",
    "print(f\"   Features techniques : {len(feature_cols)}\")\n",
    "print(f\"   Tickers : {df_features.index.get_level_values('ticker').nunique()}\")\n",
    "print(f\"   P√©riode : {df_features.index.get_level_values('date').min().date()} ‚Üí {df_features.index.get_level_values('date').max().date()}\")\n",
    "\n",
    "print(f\"\\nüìã Liste des {len(feature_cols)} features cr√©√©es :\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"   {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nüìä Statistiques descriptives :\")\n",
    "display(df_features[feature_cols].describe().T.round(3))\n",
    "\n",
    "# ============================================\n",
    "# 6. VISUALISATION (Aper√ßu)\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüìä √âTAPE 6 : Aper√ßu des donn√©es...\")\n",
    "\n",
    "print(\"\\nüîç Premi√®res lignes :\")\n",
    "display(df_features.head(15))\n",
    "\n",
    "print(\"\\nüîç Exemple pour un ticker (AI.PA) :\")\n",
    "if 'AI.PA' in df_features.index.get_level_values('ticker'):\n",
    "    display(df_features.xs('AI.PA', level='ticker').tail(10))\n",
    "\n",
    "# ============================================\n",
    "# 7. SAUVEGARDE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\nüíæ √âTAPE 7 : Sauvegarde du dataset...\")\n",
    "\n",
    "output_file = PROCESSED_DATA_PATH / \"cac40_features.csv\"\n",
    "df_features.to_csv(output_file)\n",
    "\n",
    "print(f\"‚úÖ Dataset sauvegard√© : {output_file}\")\n",
    "print(f\"   Taille du fichier : {output_file.stat().st_size / 1024 / 1024:.2f} MB\")\n",
    "\n",
    "# Sauvegarder aussi la liste des features\n",
    "features_list = pd.DataFrame({'feature': feature_cols})\n",
    "features_list_path = PROCESSED_DATA_PATH / \"features_list.csv\"\n",
    "features_list.to_csv(features_list_path, index=False)\n",
    "print(f\"‚úÖ Liste des features sauvegard√©e : {features_list_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ FEATURE ENGINEERING TERMIN√â !\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìÅ Fichiers g√©n√©r√©s :\")\n",
    "print(f\"   1. {output_file}\")\n",
    "print(f\"   2. {features_list_path}\")\n",
    "\n",
    "print(\"\\nüéØ Prochaines √©tapes :\")\n",
    "print(\"   1. Train/Test split\")\n",
    "print(\"   2. Normalisation des features\")\n",
    "print(\"   3. Mod√®le ML (LSTM, XGBoost, etc.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68056d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['garman_klass_vol'] = ((np.log(df['high'])-np.log(df['low']))**2)/2-(2*np.log(2)-1)*((np.log(df['adj close'])-np.log(df['open']))**2)\n",
    "\n",
    "df['rsi'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.rsi(close=x, length=20))\n",
    "\n",
    "df['bb_low'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,0])\n",
    "                                                          \n",
    "df['bb_mid'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,1])\n",
    "                                                          \n",
    "df['bb_high'] = df.groupby(level=1)['adj close'].transform(lambda x: pandas_ta.bbands(close=np.log1p(x), length=20).iloc[:,2])\n",
    "\n",
    "def compute_atr(stock_data):\n",
    "    atr = pandas_ta.atr(high=stock_data['high'],\n",
    "                        low=stock_data['low'],\n",
    "                        close=stock_data['close'],\n",
    "                        length=14)\n",
    "    return atr.sub(atr.mean()).div(atr.std())\n",
    "\n",
    "df['atr'] = df.groupby(level=1, group_keys=False).apply(compute_atr)\n",
    "\n",
    "def compute_macd(close):\n",
    "    macd = pandas_ta.macd(close=close, length=20).iloc[:,0]\n",
    "    return macd.sub(macd.mean()).div(macd.std())\n",
    "\n",
    "df['macd'] = df.groupby(level=1, group_keys=False)['adj close'].apply(compute_macd)\n",
    "\n",
    "df['dollar_volume'] = (df['adj close']*df['volume'])/1e6\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
